{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a75b23c2-5f5c-42e4-a5a7-09e71c609e30",
   "metadata": {},
   "source": [
    "Cell 1：设置环境与模型路径（离线模式）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662da59c-1539-47ff-9c7a-030478c1a4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: /home/dataset-assist-0/data/models/Qwen2.5-14B-Instruct\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 强制离线，避免 transformers/hf 试图联网\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "\n",
    "# 把这里改成你实际的模型目录（必须包含 config.json）\n",
    "MODEL_DIR = \"/home/dataset-assist-0/data/models/Qwen2.5-14B-Instruct\"\n",
    "\n",
    "# 验证关键文件是否存在\n",
    "import pathlib\n",
    "assert pathlib.Path(MODEL_DIR, \"config.json\").exists(), f\"找不到 config.json：{MODEL_DIR}\"\n",
    "print(\"OK:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edac9377-ab97-4dc3-ac27-babd99201505",
   "metadata": {},
   "source": [
    "Cell 2：安装依赖（只需运行一次）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36635ae8-5f26-4503-9bd3-5b245eb2f89d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install -U vllm transformers pymupdf"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9b93367-7d3d-4100-8d0a-a5358bf8779a",
   "metadata": {},
   "source": [
    "Cell 3：加载模型（vLLM in-process，不开端口）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ec9f38-54d1-4ecc-aaaa-3f73a789394f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-22 19:21:22 [utils.py:253] non-default args: {'max_model_len': 32768, 'tensor_parallel_size': 2, 'disable_log_stats': True, 'model': '/home/dataset-assist-0/data/models/Qwen2.5-14B-Instruct'}\n",
      "INFO 12-22 19:21:22 [model.py:514] Resolved architecture: Qwen2ForCausalLM\n",
      "INFO 12-22 19:21:22 [model.py:1661] Using max model len 32768\n",
      "INFO 12-22 19:21:22 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m INFO 12-22 19:21:23 [core.py:93] Initializing a V1 LLM engine (v0.13.0) with config: model='/home/dataset-assist-0/data/models/Qwen2.5-14B-Instruct', speculative_config=None, tokenizer='/home/dataset-assist-0/data/models/Qwen2.5-14B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False), seed=0, served_model_name=/home/dataset-assist-0/data/models/Qwen2.5-14B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False}, 'local_cache_dir': None}\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m WARNING 12-22 19:21:23 [multiproc_executor.py:882] Reducing Torch parallelism from 56 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m INFO 12-22 19:21:23 [parallel_state.py:1203] world_size=2 rank=0 local_rank=0 distributed_init_method=tcp://127.0.0.1:40830 backend=nccl\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m INFO 12-22 19:21:23 [parallel_state.py:1203] world_size=2 rank=1 local_rank=1 distributed_init_method=tcp://127.0.0.1:40830 backend=nccl\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m INFO 12-22 19:21:24 [pynccl.py:111] vLLM is using nccl==2.27.5\n",
      "[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m WARNING 12-22 19:21:24 [symm_mem.py:67] SymmMemCommunicator: Device capability 8.0 not supported, communicator is not available.\n",
      "WARNING 12-22 19:21:24 [symm_mem.py:67] SymmMemCommunicator: Device capability 8.0 not supported, communicator is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libibverbs: Warning: couldn't open config directory '/etc/libibverbs.d'.\n",
      "libibverbs: Warning: couldn't open config directory '/etc/libibverbs.d'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m INFO 12-22 19:21:24 [parallel_state.py:1411] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0\n",
      "INFO 12-22 19:21:24 [parallel_state.py:1411] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank 1\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:21:25 [gpu_model_runner.py:3562] Starting to load model /home/dataset-assist-0/data/models/Qwen2.5-14B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP1 pid=6149)\u001b[0;0m /opt/conda/lib/python3.11/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP1 pid=6149)\u001b[0;0m \u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m /opt/conda/lib/python3.11/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
      "\u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m \u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
      "\u001b[0;36m(Worker_TP1 pid=6149)\u001b[0;0m \u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m   warnings.warn(\n",
      "\u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:21:27 [cuda.py:351] Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/8 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  12% Completed | 1/8 [00:01<00:07,  1.13s/it]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 2/8 [00:01<00:04,  1.43it/s]\n",
      "Loading safetensors checkpoint shards:  38% Completed | 3/8 [00:02<00:04,  1.16it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 4/8 [00:03<00:04,  1.01s/it]\n",
      "Loading safetensors checkpoint shards:  62% Completed | 5/8 [00:05<00:03,  1.11s/it]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 6/8 [00:06<00:02,  1.13s/it]\n",
      "Loading safetensors checkpoint shards:  88% Completed | 7/8 [00:07<00:01,  1.15s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 8/8 [00:08<00:00,  1.19s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 8/8 [00:08<00:00,  1.09s/it]\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:21:36 [default_loader.py:308] Loading weights took 8.81 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:21:37 [gpu_model_runner.py:3659] Model loading took 13.9282 GiB memory and 10.781168 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:21:44 [backends.py:643] Using cache directory: /home/batchcom/.cache/vllm/torch_compile_cache/8dad701a84/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:21:44 [backends.py:703] Dynamo bytecode transform time: 7.31 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:21:53 [backends.py:261] Cache the graph of compile range (1, 8192) for later use\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP1 pid=6149)\u001b[0;0m INFO 12-22 19:21:53 [backends.py:261] Cache the graph of compile range (1, 8192) for later use\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:22:09 [backends.py:278] Compiling a graph for compile range (1, 8192) takes 21.41 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:22:09 [monitor.py:34] torch.compile takes 28.72 s in total\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:22:12 [gpu_worker.py:375] Available KV cache memory: 19.88 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m INFO 12-22 19:22:12 [kv_cache_utils.py:1291] GPU KV cache size: 217,088 tokens\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m INFO 12-22 19:22:13 [kv_cache_utils.py:1296] Maximum concurrency for 32,768 tokens per request: 6.62x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:03<00:00, 14.68it/s]\n",
      "Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:01<00:00, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP1 pid=6149)\u001b[0;0m INFO 12-22 19:22:18 [custom_all_reduce.py:216] Registering 8342 cuda graph addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:02<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:22:19 [custom_all_reduce.py:216] Registering 8342 cuda graph addresses\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m \u001b[0;36m(Worker_TP0 pid=6147)\u001b[0;0m INFO 12-22 19:22:19 [gpu_model_runner.py:4587] Graph capturing finished in 7 secs, took 0.82 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=6133)\u001b[0;0m INFO 12-22 19:22:19 [core.py:259] init engine (profile, create kv cache, warmup model) took 42.89 seconds\n",
      "INFO 12-22 19:22:20 [llm.py:360] Supported tasks: ['generate']\n",
      "LLM loaded.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "# 2张A800：tensor_parallel_size=2 更稳\n",
    "llm = LLM(\n",
    "    model=MODEL_DIR,\n",
    "    tensor_parallel_size=2,\n",
    "    dtype=\"auto\",\n",
    "    max_model_len=32768,   # 你也可先用 16384 跑通\n",
    ")\n",
    "\n",
    "print(\"LLM loaded.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "561d2348-20fa-4d95-9350-ab52f31cc6be",
   "metadata": {},
   "source": [
    "Cell 4：把年报读成文本（两种：txt 或 pdf）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e18f73-7698-4e37-9ddc-83fe9b0a6823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars: 677783\n"
     ]
    }
   ],
   "source": [
    "import fitz  # pymupdf\n",
    "\n",
    "def pdf_to_text(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    parts = []\n",
    "    for page in doc:\n",
    "        t = page.get_text(\"text\")\n",
    "        if t:\n",
    "            parts.append(t)\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "annual_text = pdf_to_text(\"/home/dataset-assist-0/英伟达-2025-Annual-Report.pdf\")\n",
    "print(\"chars:\", len(annual_text))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03c704a4-ae9b-4b48-b0bb-215391d7ab0c",
   "metadata": {},
   "source": [
    "Cell 5：Map-Reduce（年报很长时必用，仍然是“一键生成”）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06b1fb50-8d60-4e83-bf6f-493d070c5452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (160719 > 131072). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_count: 29\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, trust_remote_code=True)\n",
    "\n",
    "def chunk_by_tokens(text, chunk_tokens=6000, overlap_tokens=300):\n",
    "    ids = tokenizer.encode(text)\n",
    "    step = chunk_tokens - overlap_tokens\n",
    "    chunks = []\n",
    "    for start in range(0, len(ids), step):\n",
    "        end = min(start + chunk_tokens, len(ids))\n",
    "        chunks.append(tokenizer.decode(ids[start:end]))\n",
    "        if end >= len(ids):\n",
    "            break\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_by_tokens(annual_text, chunk_tokens=6000, overlap_tokens=300)\n",
    "print(\"chunk_count:\", len(chunks))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4259fd04-c59d-4640-ac10-298bdbd284d5",
   "metadata": {},
   "source": [
    "Map：每块抽取“要点卡片”（JSON）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5083317d-8a54-4ee1-b46a-f4c8e3893cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 34.70it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.19s/it, est. speed input: 748.48 toks/s, output: 60.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 31.80it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.65s/it, est. speed input: 418.59 toks/s, output: 61.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 31.70it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.60s/it, est. speed input: 419.99 toks/s, output: 61.67 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 26.32it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.63s/it, est. speed input: 419.09 toks/s, output: 61.54 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 26.25it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.58s/it, est. speed input: 420.40 toks/s, output: 61.73 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 29.29it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.70s/it, est. speed input: 915.81 toks/s, output: 59.77 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 30.21it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.58s/it, est. speed input: 420.43 toks/s, output: 61.74 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 31.64it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.24s/it, est. speed input: 462.84 toks/s, output: 61.48 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 30.88it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.60s/it, est. speed input: 419.95 toks/s, output: 61.67 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 33.05it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.61s/it, est. speed input: 419.56 toks/s, output: 61.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 30.13it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.64s/it, est. speed input: 418.59 toks/s, output: 61.47 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 26.02it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.57s/it, est. speed input: 420.83 toks/s, output: 61.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 29.17it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.59s/it, est. speed input: 420.21 toks/s, output: 61.70 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 29.25it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.62s/it, est. speed input: 419.24 toks/s, output: 61.56 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 25.74it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.61s/it, est. speed input: 419.55 toks/s, output: 61.61 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 28.06it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.61s/it, est. speed input: 419.49 toks/s, output: 61.60 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 28.99it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.63s/it, est. speed input: 418.89 toks/s, output: 61.51 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 24.32it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.62s/it, est. speed input: 419.38 toks/s, output: 61.58 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 27.92it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.56s/it, est. speed input: 420.92 toks/s, output: 61.81 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 28.64it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.63s/it, est. speed input: 419.05 toks/s, output: 61.53 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 26.97it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.59s/it, est. speed input: 420.07 toks/s, output: 61.68 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 25.67it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.64s/it, est. speed input: 418.82 toks/s, output: 61.50 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 29.29it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.61s/it, est. speed input: 419.61 toks/s, output: 61.62 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 30.22it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.66s/it, est. speed input: 418.14 toks/s, output: 61.40 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 30.57it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.57s/it, est. speed input: 420.64 toks/s, output: 61.78 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 25.80it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.60s/it, est. speed input: 419.93 toks/s, output: 61.66 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 31.05it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.61s/it, est. speed input: 419.51 toks/s, output: 61.60 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 31.64it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:14<00:00, 14.59s/it, est. speed input: 420.24 toks/s, output: 61.71 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 97.17it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.87s/it, est. speed input: 322.65 toks/s, output: 63.65 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped c029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cards = []\n",
    "map_sampling = SamplingParams(temperature=0.1, max_tokens=900)\n",
    "\n",
    "for i, ch in enumerate(chunks, 1):\n",
    "    map_prompt = f\"\"\"\n",
    "你将得到一段年报原文。请严格只根据原文提取信息，不要编造。\n",
    "输出必须是JSON（不要多余文字），字段如下：\n",
    "- chunk_id: \"c{i:03d}\"\n",
    "- facts: 3~8条事实要点（尽量包含数字）\n",
    "- financial_metrics: 若出现财务指标，用数组输出，例如 {{\"name\":\"营收\",\"value\":\"...\",\"period\":\"...\"}}\n",
    "- major_events: 0~5条重大事项\n",
    "- risks: 0~5条风险点\n",
    "- quotes: 2~5条原文短句引用（用于支撑事实/数字）\n",
    "\n",
    "【原文】\n",
    "{ch}\n",
    "\"\"\".strip()\n",
    "\n",
    "    card = llm.generate([map_prompt], map_sampling)[0].outputs[0].text\n",
    "    cards.append(card)\n",
    "    print(f\"mapped c{i:03d}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8663eaf3-5161-4f74-bfb5-238d9fd6829b",
   "metadata": {},
   "source": [
    "Reduce：用卡片写最终短 report（禁止新增事实 + 要求引用 chunk_id）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ead861c2-cb3e-4b04-9251-dfefa25066dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.17s/it, est. speed input: 1062.24 toks/s, output: 51.79 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 请确认提取的信息是否准确，如果存在错误或遗漏，请给出修改后的版本。 信息提取基本准确，但可以进一步优化和补充一些细节。以下是修改后的版本：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"chunk_id\": \"c029\",\n",
      "  \"facts\": [\n",
      "    \"公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员\",\n",
      "    \"公司执行团队包括Colette M. Kress、Jay Puri、Debora Shoquist和Timothy S. Teter\",\n",
      "    \"公司独立会计师为PricewaterhouseCoopers LLP\",\n",
      "    \"公司年度股东大会将于2025年6月25日上午9点（太平洋时间）在线举行\",\n",
      "    \"公司年报（Form 10-K）可在SEC网站和NVIDIA投资者关系网站上访问\",\n",
      "    \"公司注册地址为2788 San Tomas Expressway, Santa Clara, California 95051\"\n",
      "  ],\n",
      "  \"financial_metrics\": [],\n",
      "  \"major_events\": [\n",
      "    \"2025年6月25日召开年度股东大会\"\n",
      "  ],\n",
      "  \"risks\": [],\n",
      "  \"quotes\": [\n",
      "    \"Jensen Huang为创始人、总裁兼首席执行官\",\n",
      "    \"年度股东大会将于2025年6月25日上午9点（太平洋时间）在线举行\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "以下是进一步优化后的版本：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"chunk_id\": \"c029\",\n",
      "  \"facts\": [\n",
      "    \"公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员\",\n",
      "    \"公司执行团队包括Colette M. Kress、Jay Puri、Debora Shoquist和Timothy S. Teter\",\n",
      "    \"公司独立会计师为PricewaterhouseCoopers LLP\",\n",
      "    \"公司年度股东大会将于2025年6月25日上午9点（太平洋时间）在线举行\",\n",
      "    \"公司年报（Form 10-K）可在SEC网站和NVIDIA投资者关系网站上访问\",\n",
      "    \"公司注册地址为2788 San Tomas Expressway, Santa Clara, California 95051\"\n",
      "  ],\n",
      "  \"financial_metrics\": [],\n",
      "  \"major_events\": [\n",
      "    \"2025年6月25日召开年度股东大会\"\n",
      "  ],\n",
      "  \"risks\": [],\n",
      "  \"quotes\": [\n",
      "    \"Jensen Huang为创始人、总裁兼首席执行官\",\n",
      "    \"年度股东大会将于2025年6月25日上午9点（太平洋时间）在线举行\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "提取的信息基本准确，无需进一步修改。以下是最终确认的版本：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"chunk_id\": \"c029\",\n",
      "  \"facts\": [\n",
      "    \"公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员\",\n",
      "    \"公司执行团队包括Colette M. Kress、Jay Puri、Debora Shoquist和Timothy S. Teter\",\n",
      "    \"公司独立会计师为PricewaterhouseCoopers LLP\",\n",
      "    \"公司年度股东大会将于2025年6月25日上午9点（太平洋时间）在线举行\",\n",
      "    \"公司年报（Form 10-K）可在SEC网站和NVIDIA投资者关系网站上访问\",\n",
      "    \"公司注册地址为2788 San Tomas Expressway, Santa Clara, California 95051\"\n",
      "  ],\n",
      "  \"financial_metrics\": [],\n",
      "  \"major_events\": [\n",
      "    \"2025年6月25日召开年度股东大会\"\n",
      "  ],\n",
      "  \"risks\": [],\n",
      "  \"quotes\": [\n",
      "    \"Jensen Huang为创始人、总裁兼首席执行官\",\n",
      "    \"年度股东大会将于2025年6月25日上午9点（太平洋时间）在线举行\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "确认提取的信息准确无误。以下是最终版本：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"chunk_id\": \"c029\",\n",
      "  \"facts\": [\n",
      "    \"公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员\",\n",
      "    \"公司执行团队包括Colette M. Kress、Jay Puri、Debora Shoquist和Timothy S. Teter\",\n",
      "    \"公司独立会计师为PricewaterhouseCoopers LLP\",\n",
      "    \"公司年度股东大会将于2025年6月25日上午9点（太平洋时间）在线举行\",\n",
      "    \"公司年报（Form 10-K）可在SEC网站和NVIDIA投资者关系网站上访问\",\n",
      "    \"公司注册地址为2788 San Tomas Expressway, Santa Clara, California 95051\"\n",
      "  ],\n",
      "  \"financial_metrics\": [],\n",
      "  \"major_events\": [\n",
      "    \"2025年6月25日召开年度股东大会\"\n",
      "  ],\n",
      "  \"risks\": [],\n",
      "  \"quotes\": [\n",
      "    \"Jensen Huang为创始人、总裁兼首席执行官\",\n",
      "    \"年度股东大会将于2025年6月25日上午9点（太平洋时间）在线举行\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "提取的信息准确无误。以下是最终版本：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"chunk_id\": \"c029\",\n",
      "  \"facts\": [\n",
      "    \"公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员\",\n",
      "    \"公司执行团队包括Colette M. Kress、Jay Puri、Debora Shoquist和Timothy S. Teter\",\n",
      "    \"公司独立会计师为PricewaterhouseCoopers LLP\",\n",
      "    \"公司年度股东大会将于2025年6月25日上午9点（太平洋时间）在线举行\",\n",
      "    \"公司年报（Form 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reduce_sampling = SamplingParams(temperature=0.2, max_tokens=1200)\n",
    "\n",
    "reduce_prompt = f\"\"\"\n",
    "你将得到若干段JSON卡片（来自年报原文的抽取结果）。\n",
    "请基于这些卡片写一篇【800字以内】短report，必须包含小标题：\n",
    "1 公司概况；2 经营亮点；3 核心财务；4 风险提示；5 一句话结论。\n",
    "\n",
    "严格规则：\n",
    "- 只能使用卡片中出现的事实/数字/事件；不得新增、不得猜测。\n",
    "- 若信息缺失，请写“原文未披露”。\n",
    "- 每条关键数字或结论后加来源chunk_id，如（来源：c003,c007）。\n",
    "- 报告语言简洁、像投研摘要。\n",
    "\n",
    "【卡片】\n",
    "{chr(10).join(cards)}\n",
    "\"\"\".strip()\n",
    "\n",
    "report = llm.generate([reduce_prompt], reduce_sampling)[0].outputs[0].text\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5318c507-ca72-44fa-83ac-a5586976d873",
   "metadata": {},
   "source": [
    "Cell 6（强烈建议）：让模型做一次“自查一致性”（防胡说）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4ab68b3-e0fb-48c1-bbc4-369b48e673dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.13s/it, est. speed input: 1419.81 toks/s, output: 49.65 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 以下是检查报告中无法由卡片证据支持的内容：\n",
      "\n",
      "1. **问题句子**：公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员。\n",
      "   - **问题**：证据卡片中没有具体列出董事会成员的完整名单，只提到了部分成员。\n",
      "   - **建议**：删除或修改为“公司董事会成员包括Jensen Huang等多位成员”。\n",
      "\n",
      "2. **问题句子**：公司执行团队包括Colette M. Kress、Jay Puri、Debora Shoquist和Timothy S. Teter。\n",
      "   - **问题**：证据卡片中没有具体列出执行团队的完整名单，只提到了部分成员。\n",
      "   - **建议**：删除或修改为“公司执行团队包括Colette M. Kress等多位成员”。\n",
      "\n",
      "3. **问题句子**：公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员。\n",
      "   - **问题**：证据卡片中没有具体列出董事会成员的完整名单，只提到了部分成员。\n",
      "   - **建议**：删除或修改为“公司董事会成员包括Jensen Huang等多位成员”。\n",
      "\n",
      "4. **问题句子**：公司执行团队包括Colette M. Kress、Jay Puri、Debora Shoquist和Timothy S. Teter。\n",
      "   - **问题**：证据卡片中没有具体列出执行团队的完整名单，只提到了部分成员。\n",
      "   - **建议**：删除或修改为“公司执行团队包括Colette M. Kress等多位成员”。\n",
      "\n",
      "5. **问题句子**：公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员。\n",
      "   - **问题**：证据卡片中没有具体列出董事会成员的完整名单，只提到了部分成员。\n",
      "   - **建议**：删除或修改为“公司董事会成员包括Jensen Huang等多位成员”。\n",
      "\n",
      "6. **问题句子**：公司执行团队包括Colette M. Kress、Jay Puri、Debora Shoquist和Timothy S. Teter。\n",
      "   - **问题**：证据卡片中没有具体列出执行团队的完整名单，只提到了部分成员。\n",
      "   - **建议**：删除或修改为“公司执行团队包括Colette M. Kress等多位成员”。\n",
      "\n",
      "7. **问题句子**：公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员。\n",
      "   - **问题**：证据卡片中没有具体列出董事会成员的完整名单，只提到了部分成员。\n",
      "   - **建议**：删除或修改为“公司董事会成员包括Jensen Huang等多位成员”。\n",
      "\n",
      "8. **问题句子**：公司执行团队包括Colette M. Kress、Jay Puri、Debora Shoquist和Timothy S. Teter。\n",
      "   - **问题**：证据卡片中没有具体列出执行团队的完整名单，只提到了部分成员。\n",
      "   - **建议**：删除或修改为“公司执行团队包括Colette M. Kress等多位成员”。\n",
      "\n",
      "9. **问题句子**：公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员。\n",
      "   - **问题**：证据卡片中没有具体列出董事会成员的完整名单，只提到了部分成员。\n",
      "   - **建议**：删除或修改为“公司董事会成员包括Jensen Huang等多位成员”。\n",
      "\n",
      "10. **问题句子**：公司执行团队包括Colette M. Kress、Jay Puri、Debora Shoquist和Timothy S. Teter。\n",
      "    - **问题**：证据卡片中没有具体列出执行团队的完整名单，只提到了部分成员。\n",
      "    - **建议**：删除或修改为“公司执行团队包括Colette M. Kress等多位成员”。\n",
      "\n",
      "11. **问题句子**：公司董事会成员包括Jensen Huang、Robert K. Burgess、Tench Coxe等12位成员。\n",
      "    - **问题**：证据卡片中没有具体列出董事会成员的完整名单，只提到了部分成员。\n",
      "    - **建议**：删除或修改为“公司董事会成员包括Jensen Huang等多位成员”。\n",
      "\n",
      "12. **问题句子**：公司执行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_prompt = f\"\"\"\n",
    "你是审稿人，只检查一致性。\n",
    "请找出短report中任何无法由卡片证据支持的内容（数字/事件/结论），逐条列出并建议删除或改写。\n",
    "输出格式：\n",
    "- 问题句子：...\n",
    "- 问题：...\n",
    "- 建议：...\n",
    "\n",
    "【短report】\n",
    "{report}\n",
    "\n",
    "【证据卡片】\n",
    "{chr(10).join(cards)}\n",
    "\"\"\".strip()\n",
    "\n",
    "check = llm.generate([check_prompt], SamplingParams(temperature=0.0, max_tokens=900))[0].outputs[0].text\n",
    "print(check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991e656-8e6b-42e6-bdb9-b2f8bc692916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
